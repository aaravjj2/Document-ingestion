"""create_tables_with_string_enums

Revision ID: 82fb2032ae16
Revises: 001_initial
Create Date: 2025-12-30 17:19:09.453507

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "82fb2032ae16"
down_revision: Union[str, None] = "001_initial"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "documents",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("filename", sa.String(length=255), nullable=False),
        sa.Column("original_filename", sa.String(length=255), nullable=False),
        sa.Column("file_path", sa.String(length=512), nullable=False),
        sa.Column("file_size", sa.Float(), nullable=True),
        sa.Column("mime_type", sa.String(length=100), nullable=True),
        sa.Column("page_count", sa.Float(), nullable=True),
        sa.Column("status", sa.String(length=50), nullable=False),
        sa.Column("document_type", sa.String(length=50), nullable=True),
        sa.Column("classification_confidence", sa.Float(), nullable=True),
        sa.Column("ocr_confidence", sa.Float(), nullable=True),
        sa.Column("raw_text", sa.Text(), nullable=True),
        sa.Column("text_search_vector", postgresql.TSVECTOR(), nullable=True),
        sa.Column("upload_timestamp", sa.DateTime(), nullable=False),
        sa.Column("processing_started_at", sa.DateTime(), nullable=True),
        sa.Column("processing_completed_at", sa.DateTime(), nullable=True),
        sa.Column("error_log", sa.Text(), nullable=True),
        sa.Column("retry_count", sa.Float(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index("idx_documents_status", "documents", ["status"], unique=False)
    op.create_index(
        "idx_documents_text_search",
        "documents",
        ["text_search_vector"],
        unique=False,
        postgresql_using="gin",
    )
    op.create_index("idx_documents_type", "documents", ["document_type"], unique=False)
    op.create_index(
        "idx_documents_upload_timestamp", "documents", ["upload_timestamp"], unique=False
    )
    op.create_index(op.f("ix_documents_status"), "documents", ["status"], unique=False)
    op.create_table(
        "extracted_metadata",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("document_id", sa.UUID(), nullable=False),
        sa.Column("document_type", sa.String(length=50), nullable=True),
        sa.Column("data", postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column("extraction_model", sa.String(length=100), nullable=True),
        sa.Column("extraction_confidence", sa.Float(), nullable=True),
        sa.Column("extraction_timestamp", sa.DateTime(), nullable=True),
        sa.Column("is_validated", sa.Float(), nullable=True),
        sa.Column("validated_by", sa.String(length=100), nullable=True),
        sa.Column("validated_at", sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(["document_id"], ["documents.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("document_id"),
    )
    op.create_index(
        "idx_metadata_data", "extracted_metadata", ["data"], unique=False, postgresql_using="gin"
    )
    op.create_index(
        "idx_metadata_document_type", "extracted_metadata", ["document_type"], unique=False
    )
    op.create_table(
        "ocr_results",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("document_id", sa.UUID(), nullable=False),
        sa.Column("page_number", sa.Float(), nullable=False),
        sa.Column("text", sa.Text(), nullable=False),
        sa.Column("confidence", sa.Float(), nullable=False),
        sa.Column("bounding_box", postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column("sequence_order", sa.Float(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(["document_id"], ["documents.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "idx_ocr_document_page", "ocr_results", ["document_id", "page_number"], unique=False
    )
    op.create_table(
        "processing_queue",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("document_id", sa.UUID(), nullable=False),
        sa.Column("celery_task_id", sa.String(length=255), nullable=True),
        sa.Column("priority", sa.Float(), nullable=False),
        sa.Column("queued_at", sa.DateTime(), nullable=True),
        sa.Column("started_at", sa.DateTime(), nullable=True),
        sa.Column("completed_at", sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(["document_id"], ["documents.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "idx_queue_priority", "processing_queue", ["priority", "queued_at"], unique=False
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index("idx_queue_priority", table_name="processing_queue")
    op.drop_table("processing_queue")
    op.drop_index("idx_ocr_document_page", table_name="ocr_results")
    op.drop_table("ocr_results")
    op.drop_index("idx_metadata_document_type", table_name="extracted_metadata")
    op.drop_index("idx_metadata_data", table_name="extracted_metadata", postgresql_using="gin")
    op.drop_table("extracted_metadata")
    op.drop_index(op.f("ix_documents_status"), table_name="documents")
    op.drop_index("idx_documents_upload_timestamp", table_name="documents")
    op.drop_index("idx_documents_type", table_name="documents")
    op.drop_index("idx_documents_text_search", table_name="documents", postgresql_using="gin")
    op.drop_index("idx_documents_status", table_name="documents")
    op.drop_table("documents")
    # ### end Alembic commands ###
